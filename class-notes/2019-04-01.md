# Index Structures (cont'd)

## B-Trees

### Applications of B-Trees

- Search key of the b-tree is the primary key for the data file, the index is dense: One key-pointer pair for every record in the data file.
- The data file is sorted by its primary key. The b-tree is a sparse index: one key-pointer pair for every block of the data file
- The data file is sorted by an attribute that is not a key, and this attribute is a search key for the b-tree: one key-pointer pair for for every value k of the search key that appears. The pointers in this case are to the first instance of k.

Note that we can have B-Trees that allow for multiple instances of a search key. 

In such cases, the key values in each node might not all be filled. 

For the purposes of this class, we'll assume no duplicates. We'll also assume a dense index: every search key value in the data file also appears at a leaf. 

#### Lookup in B-Trees:

Recursive Algorithm. Search for some key value k.

Basis: If we're at a leaf node , if the ith key is k, the ith pointer points to a record containing k. 

Induction: Interior node with keys k1, k2, ..., kn.
    - If k < k1: follow the first pointer
    - If k >= k1 and k < k2, follow the second pointer, and so on
    - Else (k >= kn): follow n+1 pointer. 

Range Queries: find all values between a and b. 

Search for a. Whether or not it exists, we end up at a leaf node (where it would exist). Then we can follow every associated pointer, using the (n+1) pointers to jump to the next leaf, until we reach b. 

#### Insertion in B-Trees:

Recursive process:
- Find the appropriate leaf, and insert if there's room. 
- If there isn't sufficient space, split the leaf, and divide the contents equally between new and old node. 
    - Splitting the leaf appears as an insertion at the next level. 
    - The only exception is if the root is full, in which case we split the root, and create a new root at an additional level. 

When we split a leaf node, we carefully manage its keys:
- Now we have n+1 keys. We create the new node to the "right" of the existing node.
- We take the first (n+1)/2 (rounding up) keys and pointers, and leave them in the existing node
- We take the last (n+1)/2 (rounding down) keys and pointers, and move them to the new node
- We take the existing n+1 pointer and move it to the new node, create a pointer to the new node in the n+1 position for the existing node.

Slightly different for an interior node (we have n+1 keys and n+2 pointers to distribute)
- Leave the first (n+2)/2 (rounding down) pointers in place
- Move the last (n+2)/2 (rounding down) pointers to the new node
- Leave the first n/2 keys in place
- Move the last n/2 keys to the new node 
- There will be one leftover key in the exact middle. This is the vlue that's inserted as the key at the next level. 

#### Deletion in B-Trees:

We do a search and delete the key-pointer pair

However, it's possible that the deletion drops the space used below the 50% threshold. If an adjacent node has more than the minimum, we move a key-pointer pair from it. Otherwise, we combine the two to create a full node. 

#### Efficiency of B-Trees

B-Trees typically have levels. With n as 340 (as in our example), it can contain ~16 million records 

Lookup requires 3 reads. The root is commonly cached in memory. 

Most inserts and deletes only require the same. 

## Hash Tables

A hash table is a data structure that organizes data using a hash function, which takes input and returns an integer between 0 and B-1, where B is the number of buckets in the hash table. 

A bucket array is an array, indexed from 0 to B-1 that holds the heads of linked lists. 

If a record has search key k, we store it in the bucket list for the bucket numbered H(k). 

### Secondary storage hash tables

A hash table may hold too many records to fit into main memory. If the records are kept in secondary storage, we make a few alterations from a "normal" hash table.

The bucket array consists of blocks, rather than linked lists.

Assume that the location for the first block in any bucket can be determined. 
- Maybe a main memory array of pointers to blocks 
- Buckets in fixed, consecutive locations on disk. 

Each block holds records and a "nub" with additional info, like pointers to overflow blocks.

Insertion into a hashtable:

Compute H(k), determine the block. If there's sufficient space, we add the record. If not, create an overflow block. 

Deletion from a hashtable:

Similar to insert. If we can consolidate blocks, we do. 

### Choice of Hash Function

The hash function should produce an even distribution of keys of the range of the function. 

It should be easy to compute. 

Common choice for integers is k % B 

### Efficiency of Hash Tables

Ideally, there are enough buckets that most of them fit in one block. Then lookup takes only 1 i/o.

Significantly better than sparse indexes or B-trees. 

However, as the file grows, we'll end up with multiple overflow blocks, potentially long lists (many i/o's per lookup).

Good reason reason to try and keep the number of blocks per bucket low. 

So far, we've only considered *static hash tables*.

There are also *dynamic hash tables* that grow and shrink the size of the bucket array.

Two basic approaches: Extensible Hashing, Linear Hashing.

### Extensible Hash Tables

4 Major differences from static hash tables:
1. Level of indirection for buckets: the array of pointers is to buckets, not blocks themselves. 
2. The array can grow in length. It's always a power of 2.
3. There doesn't have a block for each bucket. Buckets can share blocks under certain circumstances
4. Hash function computes a sequence of k bits, for some large value of k (e.g., 32).
    - Only the first i bits are used.
    - The size of the array is 2^i

#### Insertion into an extensible hash table

- Compute H(k) for the search key k
- Consider the first i bits, go to the bucket for that value.
- Arrive at block B 
    - If there's space, insert the record. 
    - If j < i: split B into 2 blocks
        - Distribute the records in B based on the the value of their j+1 bit
        - Put j+1 in each block's nub
        - Adjust the pointers in the bucket array as necessary
        - Note: this may not solve the problem. Repeat as necessary
    - If j=i: Increment i
        - Double the lenth of the bucket array, so that it's now 2^(i+1)
        - Given some w determined by the first i bits, there are now two buckets: w0 and w1
            - Both now point to the same block as w.
        - Now j < i, and we can split the block as in the previous case 

**Advantages of Extensible Hashtables**

Never have to retrieve more than one block

**Disadvantages of Extensible Hashtables**

- Doubled array may no longer fit in main memory, or may crowd out other data we'd want in memory. 
- If the number of records per block is small, we're likely to see a block that is split earlier than necessary. 

### Linear Hashing

Grows the buckets more slowly 

Differences/New Elements:
- Number of buckets n is always chosen so that the average of records per block is a fixed fraction (e.g. 80%)
- Blocks cannot be split, so overflow blocks are permitted (the number of overflows per bucket averages less than 1)
- Number of bits used to determine the entries of the bucket array is Log2(n), where n is the current number of buckets. **These bits are always taken from the right (least significant)**
- Suppose i bits are being used to number the array entries. A record with key K is intended for bucket a1a2...ai (the last i bits) 
    - Treat a1a2...ai as integer m
    - If m < n, the bucket must exist, we insert our record there. 
    - If n <= m < 2^i, the bucket doesn't exist yet. Use the bucket represented by m - 2^(i-1)
- Each time we do an insert, we compare the number of records to the number of blocks. If the number is too great, we add a new bucket
    - If the number of buckets exceeds 2^i, increment i. All buckets now have a leading 0, but it doesn't matter, since we treat them as integers. 

## Multidimensional Indexes

All indexes seen so far have been one-dimensional. They may include multiple attributes, but they don't function well if an attribute is missing or unknown.

Applications of multidimensional indexes include Geographic Information Systems. (Often not done well by SQL)

Obviously used for maps, also used for integrated circuit design and UX layout. 

Typical queries for a GIS:
- Partial Match Query: we specify values for a subset of the attributes and look for all matches
- Range Queries: given ranges for one or more of the dimensions, find all points within the ranges
- Nearest Neighbor: Ask for the closest point to some given search point. 
- Where Am I queries: given a point, what shapes contain that point.

Conventional indexes will support these to an extent:

Range queries:

Build a B-Tree index on each dimension. Execute a range query for each dimension and obtain a set of pointers. We take the intersection of the sets of pointers. 

Nearest neighbor search: we pick an arbitrary range in each dimension and execute a query. Two possible failures:
- No point in the range
- Closer point is actually outside the given range.

We can address the first by gradually expanding the range

We address the second by executing the query again with a slightly larger range to confirm. 

### Overview of Multidimensional Indexes 

Similar to one-dimensional indexes, structures fall into two categories: Hash-Table-like structures, and Tree-like structures.

In both cases, we give up something to gain the added dimension(s). 

Hash structures will not answer queries with just one bucket. 

Tree structures give up at least one of:
- Balance of the tree 
- Correspondence between tree nodes and disk blocks
- Speed of modifications

### Hash Structures

#### Grid Files:

In each dimension, the space is partition into "stripes" with *grid lines*.

Number of grid lines may vary between dimensions. And the space between them may also vary.

Lookups: we use an n-dimensional bucket array. 

The "hash" function isn't quite the same. We need to know the location of the grid lines in each dimension. 

Insertion is similar. There's of when a bucket is full. Options are:
- Add overflow buckets or
- Reorganize by adding or moving grid lines. 

#### Partitioned Hash Function

Essentially, we concatenate the results of multiple hash functions. 

Example: use 12 bits first 4 for the first dimension, and last 8 for the second dimension. 

Comparison with grid files:

Partitioned hash tables are fairly useless for nearest-neighbor and range searches. 

Grid files tend to leave a large number of buckets mostly empty, whereas a well-designed hash function will distribute evenly. 

### Tree-like Structures

4 basic types

#### Multiple-key indexes

Basic idea is that we build an index of indexes. 

Partial match queries work well if we have the first attribute. 

Range queries and nearest neighbor tend to work quite well.

#### kd-tree

K-dimensional search tree. 

Binary tree tree, where each interior node has an attribute a and value V for that attribute that splits the data set in half. 