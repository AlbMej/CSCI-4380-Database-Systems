# Logging (cont'd)

``` 
a := a * 2
b := b * 2

Action      t       MemA    MemB    DiskA   DiskB   Log
-------------------------------------------------------
                                    5       8       Start T
Input(a)            5               5       8
Input(b)            5       8       5       8
Read(a, t)  5       5       8       5       8
a := a*2    10      5       8       5       8
Write(a, t) 10      10      8       5       8       <T, a, 5>
Read(b, t)  8       10      8       5       8
b := b*2    16      10      8       5       8       
Write(b, t) 16      10      16      5       8       <T, b, 8>
Flush Log
Output(a)   16      10      16      10      8
Output(b)   16      10      16      10      16
                                                    Commit T
Flush Log 

```

## Redo Logging

Undo logging has the problem that we can't commit any transaction until all the changes are written to disk.

We may save I/Os if changes are allowed to remain in memory for a while.

Redo logging addresses that problem

Main differences from Undo Logging:
- Redo logging repeats the effects of committed transactions, rather than undoing the not-committed transactions
- Redo Logging requires the `COMMIT` record be written to disk before any data changes are written to disk
- Update records record the new value, instead of the old.

**Redo Logging Rule**: Before writing any change to disk, both the update record and the `COMMIT` record must be written to disk.

``` 
a := a * 2
b := b * 2

Action      t       MemA    MemB    DiskA   DiskB   Log
-------------------------------------------------------
                                    5       8       Start T
Input(a)            5               5       8
Input(b)            5       8       5       8
Read(a, t)  5       5       8       5       8
a := a*2    10      5       8       5       8
Write(a, t) 10      10      8       5       8       <T, a, 10>
Read(b, t)  8       10      8       5       8
b := b*2    16      10      8       5       8       
Write(b, t) 16      10      16      5       8       <T, b, 16>
                                                    Commit T
Flush Log
Output(a)   16      10      16      10      8
Output(b)   16      10      16      10      16
                                                    
```

### Recovery

- Ignore incomplete transactions
- Identity committed transactions
- Start at the beginning of the log, and replay the Committed Transactions
- Write `ABORT T` record for each uncommitted transaction

### Checkpointing 

A little more complicated than undo logging: we have to keep track of which buffers in memory are *dirty*

But we can checkpoint without waiting for active transactions to finish, since they can't write anyway.

1. Write START CKPT(T1, T2, ... Tk) (where the Ts are the active transactions)
    - Flush Log
2. Write to disk all the dirty buffers for the completed transactions
3. Write END CKPT record
    - Flush Log

#### Recovery

Two cases, depending on if the last record is START CKPT or END CKPT

- END CKPT: everything prior to the preceding START CKPT was written to disk:
    - Any Transaction listed in that START CKPT record, or after, may have unwritten changes 
    - We can ignore everything before the earliest START Ti record 
- START CKPT: We can't be sure that the transactions committed prior to the checkpoint had their buffers written to disk.
    - We have to search back to the previous END CKPT record, as in the preceding case 

## Undo/Redo Logging

Drawbacks of Undo and Redo logging:
- Undo: data must written to disk immediately, potentially increasing I/Os 
- Redo: must keep all modified blocks in memory until the end of the transaction, increasing memory requirements 
- Both: put contradictory requirements on the buffer manager during checkpointing

**Undo/Redo Logging Rule**: Before modifying any X on disk, the update record <T, X, v, w> must appear on disk

*Note* We have to log both the old and new value in the log

``` 
a := a * 2
b := b * 2

Action      t       MemA    MemB    DiskA   DiskB   Log
-------------------------------------------------------
                                    5       8       Start T
Input(a)            5               5       8
Input(b)            5       8       5       8
Read(a, t)  5       5       8       5       8
a := a*2    10      5       8       5       8
Write(a, t) 10      10      8       5       8       <T, a, 5, 10>
Read(b, t)  8       10      8       5       8
b := b*2    16      10      8       5       8       
Write(b, t) 16      10      16      5       8       <T, b, 8, 16>
Flush Log
                                                    
Output(a)   16      10      16      10      8
                                                    
Output(b)   16      10      16      10      16
                                                    Commit T?
Flush Log
                                                    
```

### Recovery 

- Redo all the committed transactions, earliest first (start at the beginning of the log)
- Undo all the uncommitted transactions, latest first (from the end of the log)

**Side effect** of the delayed commit: it can lead to wasted work if the transaction was finished but the commit record wasn't flushed to the log. Then the transaction is unnecessarily undone.

Possible solution: **second undo/redo logging rule**: always flush the log immediately after writing the `COMMIT` record

### Checkpointing

- Write START CKPT(T1, T2, ... Tk)
    - Flush Log
- Write *all* dirty buffers to disk
- Write END CKPT

# NoSQL

Relational databases have been around a long time and have lots of advantages, especially with query performance 

As computing has changed, we've moved from monolithic applications towards very distributed applications 

Rigidity of SQL can be a disadvantage

NoSQL is the umbrella term for a growing number of alternatives to the traditional relational database

4 Basic types of NoSQL
- Document databases: key-value pairs, where the values are a complex type
- Graph Stores (Neo4J, Giraph)
- Key-value stores (simplest NoSQL): BerkelyDB, Redis
- Wide-column stores: databases that are optimized for very large datasets
    - Columns are stored together, rather than rows 
    - Cassandra, HBase

## Benefits of NoSQL

- Often more scalable 
- Can have a higher performance for some operations 
- Data model handles things the relational model won't
    - Large volumes of rapidly changing unstructured data 
    - Agile development with a quick release cycle and frequent schema changes 
- Geographically distributed databases 

NoSQL can have dynamic schema
- Schema doesn't have to be defined before you start adding data

With large relational databases, schema changes can involve downtime or complex upgrade/update procedures 

With NoSQL, the validation is often done by the application 

### Sharding

Relational databases scale vertically: a single server hosts all the data to allow for joins, transactions, etc.

Sharding involves splitting the data over a number of servers by splitting it "horizontally:" A single table is split over multiple servers by moving some of its rows to a different database instance. 

Considerable performance gains are possible

Disadvantages:
- Heavier reliance on the interconnection between servers 
- Increased latency when querying 
- Data is only sharded on one axis: some queries become slow (or impossible)
- Hard to reason about or guarantee consistency of the data 

NoSQL DBMS sometimes support "auto-sharding" taking some of the complexity out of the hands of the application developer

Distributed approach also makes replication of the data easier than many relational databases.

## Disadvantages of NoSQL

- Transaction support is minimal
- Data consistency is often not guaranteed
- Data must often be validated by the application 

## Document Model

Relational Model is effectively based on tables. There usually isn't a good mapping between the data structures used by an application and the structure of the data in a relational database.
    - Called the object-relational impedance mismatch
    - Can be addressed by ORM (object-relation mapping)
    - Adds complexity, additional code which must be learned/written and managed

Document storage databases are based on a single data structure: documents.

Related data is embedded in sub-documents

In MongoDB, documents are JSON documents
- Has many of the advantages of semi-structured discussed previously
    - Data is self-described
    - Lower barriers to entry for new developers 

MongoDB stores JSON documents as BSON (Binary JSON)
- Allows for encoding of other data types like floats, longs, dates, decimal128 (lossless decimal)
- Documents correspond to objects in many programming languages 
- Embedded documents often reduce the need for expensive joins 
- Dynamic schema supports polymorphism 

BSON documents are stored in *collections*

Collections are stored in databases

``` 
use example

db.myCollection.insertOne({
    "course": "Database Systems",
    "semester": "S19"
})

db.myCollection.insertOne({
    "other": "field",
    "second": 10
})

db.myCollection.insertOne({
    "my": "object",
    "_id": 123
})

db.myOtherCollection.insertOne({
    "my": "object2",
    "_id": 123
})


```

By default, a collection doesn't require its documents to have a schema. You *can* define document validation rules.

You can modify a document's schema simply by modifying the document 

You can create read-only views of a collection 

Fundamentally, a document is a set of key-value pairs

Field names have the following restrictions:
- `_id` is reserved for use as the primary key 
    - The value for the `_id` field must be unique across the collection
    - Is immutable
    - Can't be an array
- Field names can't contain null
- Top-level field names can't start with a `$`

Technically, field names don't have to be unique. But you'd need a data structure in the application that supported non-unique fields

Dot Notation: as XPath uses `/` between elements, JSON and MongoDB uses dot notation

Max document size is 16mb. Larger documents can be stored using the GridFS API. 

### Mongo Shell

MongoDB provides an interactive shell (similar to psql)

Based on JavaScript

`db.collection.find()` returns a cursor
- can be assigned to a variable
- Otherwise, it prints the first 20 results

`db.collection.find().pretty()` prints the results in a formatted way

For multiple lines, end with an open ( { or [

The shell executes syntactically complete statments 

Tab completion 

`quit()` (or ctrl-c)

### CRUD Operations (Create, Read, Update, Delete)

#### Create

``` 
db.collection.insertOne({...}) 

or 

db.collection.insertMany()
```

#### Read

`db.collection.find()` is similar to `SELECT * FROM collection`

We use query filters to do the selection

``` 
{
    fieldName: {
        operator: value
    }
}

db.myCollection.find({
    "course": "Database Systems"
})

db.myCollection.find({
    "course": {
        "$in": ["Database Systems"]
    }
})
```

Operators:
- `$in` checks if the value is in some array
- `$lt $gt $lte $gte $eq $ne `
- boolean operators ($and, $or, $not, $nor)
- $exists checks for the existence of the field
- $type: checks if the field is of the specified type 

Many more

#### Updates

`db.collection.updateOne({filter}, {update}, options)`

Filter object is the same as for `.find()`

Update object: 

``` 
{ 
    update operator: {
        field: value, 
        field2, value2
    },
    update operator : {
    
    }
}
```

Operators:
- `$set`
- `$inc`, $currentDate
- $min does the update if the value is above a certain minimum (also $max)
- $rename
- $unset

Many more

#### Deletes

`db.collection.deleteOne({})`

Accepts a filter object 