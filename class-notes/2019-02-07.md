# SQL Queries (cont'd)

## Subqueries

Fall into three general uses in queries:
- Scalar value
- As a relation in the WHERE clause
- As a relation in the FROM clause

### Correlated subqueries

In the simplest nested queries, the subquery is evaluated once, and the result is used in the containing query

More complicated queries require the subquery to be evaluated once for each assignment of a value of some term that comes from a tuple variable outside the subquery

Example: We want to list all the students who have failed an assignment 

```postgresql
SELECT name
FROM student 
WHERE .6 > ANY (
  SELECT grade
  FROM grades
  WHERE email = grades.student_email
);

```

### Scoping rules 

In general, an attribute is assumed to come from a relation in the FROM clause

If none exists, look in the surrounding query, and so on

We can force the surrounding query to be used by using a dot and the tuple variable

## Joins in SQL

SQL supports a number of variants on the Join operator: products, natural joins, theta joins, outer joins

Simplest is the `CROSS JOIN`: same as the cross product (Cartesian product)

`R CROSS JOIN S`

Rarely useful by itself

More conventional theta join uses the `ON` keyword

`R JOIN S ON(condition)`

``` 
SELECT *
FROM R, S 
WHERE condition
```

### Natural Joins

A natural join differs from a theta join in that:
1. The join condition is that all pairs of attributes having a common name are equated
2. One attribute from each pair is projected out 

Keyword `NATURAL JOIN` replaces the join symbol from relational algebra

### Outer Joins

SQL uses `NULL` to pad dangling tuples

`R NATURAL FULL OUTER JOIN S`

We also have the same `RIGHT` and `LEFT` variations (instead of `FULL`)

We can leave out `NATURAL` and use `ON` if we want the theta-join variant 

`R LEFT JOIN S ON (condition)`

```postgresql
SELECT * from grades;

SELECT * from student;

SELECT name, email
FROM student LEFT JOIN grades ON(student.email = grades.student_email);

SELECT *
FROM student NATURAL JOIN grades;
``` 

## Full Relation Operators

Some operators act on full relations, rather than individual tuples

### Duplicate elimination

SQL doesn't remove duplicates by default 

We can use the `DISTINCT` keyword to remove duplicates:

```postgresql
SELECT DISTINCT student_email
FROM grades;
```

Remember that duplicate elimination can be a very expensive operation

The relation must be sorted or partitioned so that duplicate tuples are next to each other

Often more costly than the rest of the query

Use judiciously 

### Grouping and Aggregation in SQL

SQL supports the grouping operator from our extended relational algebra

Supports the same five aggegration operators: `SUM`, `AVG`, `MIN`, `MAX`, and `COUNT`

Usually applied to scalar values, often an attribute in the SELECT clause

Exception is `COUNT(*)`, which counts all the tuples in the relation generated by the FROM and WHERE clause

We can eliminate duplicates in the column before the aggregation is done using the `DISTINCT` keyword

`SELECT COUNT(DISTINCT A)`

Note that `SELECT COUNT(A)` produces the same result as `SELECT COUNT(*)` because the former will count duplicate values in the `A` column

### Grouping

Use the key words `GROUP BY <attributes>`

Followed by a list of grouping attributes. The aggregated attributes appear in the SELECT clause

Only two kinds of attributes can appear in a SELECT clause once you have the `GROUP BY` keywords:
1. Aggregations 
2. Attributes that appear in the GROUP BY clause 

There's no requirement to have both. You could have just aggregated attributes or just grouping attributes

```postgresql
SELECT student_email, AVG(grade), course_name
FROM grades
GROUP BY student_email, course_name;

SELECT student_email, AVG(grade), course_name
FROM grades, course
WHERE course.semester = 'S19'
GROUP BY student_email, course_name;


select * from grades;
```

We can have `GROUP BY` in a query involving multiple relations. The query happens in the following order:
1. Evaluate the relation R created by the `FROM` and `WHERE` clauses
2. Group the tuples of R according to the grouping attributes (in the `GROUP BY` clause)
3. Produce the result specified in the SELECT clause

#### Handling Nulls

There are a few rules:
- The "value" `NULL` is ignored in any aggregation, including `COUNT(A)`. Note that `COUNT(*) will still count all the tuples in the relation. `COUNT(A)` is the number of non-null values in A
- `NULL` is treated as an ordinary value when it comes to building groups
- When we perform any aggregation except `COUNT` over an empty bag, the result is `NULL`. The count of an empty bag is 0.

### Having clause

What if we don't want to include every tuple in our grouping result?

One option is to restrict which tuples are included using the WHERE clause

But sometimes we want to limit which groups appear based on the result of some aggregation 

Find students above some average score (.73)

We use `HAVING <condition>` to restrict which groups will appear in the result

```postgresql

SELECT student_email, AVG(grade)
FROM grades
GROUP BY student_email
HAVING AVG(grade) > .73;

SELECT student_email, average
FROM (
  SELECT student_email, AVG(grade) average
  FROM grades
  GROUP BY student_email) average_grades
WHERE average > .73;

```

Rules to remember:
- An aggregation in a `HAVING` clause applies only to the tuples in the group being tested
- Any attribute in a relation in the FROM clause may be aggregated in the HAVING clause, but only those attributes that appear in the GROUP BY list may appear unaggregated in the HAVING clause (same as for the SELECT)

# Database Modification

So far, we've seen SQL statements that return tuples. There are others that allow modification of the data. We'll focus on three types:
- INSERT 
- DELETE
- UPDATE

## Insertion

Basic form is `INSERT INTO relation(list of attributes) VALUES(list of values);`

If the list of attributes doesn't include all the attributes of the relation, the missing attributes will be populated by default values (or NULL)

The list of attributes is technically optional. If omitted, the values are populated in the "standard order"

The list of attributes is recommended if the order of attributes is unknown

```postgresql
INSERT INTO student(name, email, major) VALUES('dave', 'dave@example.com', 'ARCH');

INSERT INTO student VALUES('edward', 'ed@example.com', 'CSCI');

INSERT INTO student VALUES('faith@example.com', 'faith', 'CSCI');

INSERT INTO student(name, email) VALUES ('george', 'george@example.com');

INSERT INTO student(email, major, name) VALUES ('harry@example.com', 'CSCI', 'harold');

SELECT * FROM student;

```

Using the `VALUES` keyword inserts a single tuple. We can insert many tuples using a subquery

```postgresql
INSERT INTO course(name, semester) VALUES('Ethics', 'F19');

SELECT * from enroll;

INSERT INTO enroll(student_email, course_name, semester) (
  SELECT email, 'Ethics', 'F19'
  FROM student
  WHERE major = 'CSCI'
);

SELECT email, 'Ethics', 'F19'
  FROM student
  WHERE major = 'CSCI';
```

## Deletion

`DELETE FROM relation WHERE condition`

```postgresql
SELECT * FROM student;

DELETE FROM student WHERE email NOT LIKE '%@%.%';
```

## Updates

`UPDATE relation SET <assignments> WHERE condition`

Each assignment statement is an attribute followed by `=` followed by an expression, separated by commas

```postgresql
UPDATE student SET major='CHEM' WHERE name = 'george';

UPDATE student SET email='carol@example.com', major='CHEM' WHERE name='carol';

SELECT * from student;

```

# Transactions in SQL

So far, we've only considered one user modifying the database. In reality, it's much more complicated. 

SQL provides some tools to help deal with the common situation where multiple users are making changes concurrently, or where operations fail to fully execute. 

## Serializability 

In many applications (web applications, banking, reservation systems, etc.), we might need to support hundreds of operations per second.

It's possible that some of those operations will overlap on the same data.

``` 
T1              T2

Check seats
                Check seats 

Reserve seat
                Reserve seat

```

SQL allows a database programmer to state that a certain set of commands must execute as if they were performed serially.

This is commonly implemented by locking certain data elements so that only one function at a time can access them 

## Atomicity

It's possible for a crash or interruption to leave the database in an unacceptable state

Example: bank transfer

``` 
Query for first balance: $500

Deduct amount from first account $400

Query for second balance: $50

Add amount to second account $150

```

SQL provides us witha  way to state that a set of commands should execute atomically (all or nothing)

## Transactions

The solution to both serializability and atomicity in SQL is *transactions*

A transaction is a collection of one or more SQL statements that must be executed atomically. SQL also requires that, by default, transactions be executed in a serial manner. 

When we use a generic SQL interface, each statement is in a transaction by itself.

The SQL command: `START TRANSACTION` starts a transaction

Postgres: `BEGIN`

From there, there are two ways to end the transaction:
- `COMMIT`: ends the transaction successfully, SQL makes its effects permanent. Prior to that, any changes are tentative and may or may not be visible to other transactions 
- `ROLLBACK`: aborts all modifications made during the transaction

Note that in Postgres, if any statement throws an error, the transaction must be rolled back

### Read Only Transactions

Previous examples (airline, class registration, bank account) required a read and a write

Difficult to parallelize 

If a transaction only reads data, we can parallelize 

If we can mark a transaction as read only, SQL can potentially leverage that information. Multiple read-only transactions can safely read the same data concurrently.

`SET TRANSACTION READ ONLY` sets the next transaction. It must be executed before the transaction. 

(Opposite in Postgres)

`SET TRANSACTION READ WRITE` sets it back to the default

### Dirty Reads

*Dirty Data* is the common term for data that has been written by a transaction that hasn't yet committed.

A *Dirty Read* is a read of dirty data by another transaction

The risk of a dirty read is that the transaction that wrote the dirty data will abort/rollback. 

Dirty reads avoid:
- The time consuming work by the DBMS needed to avoid them
- loss of parallelism that results from waiting transactions to commit

Consider a bank transfer:
1. Add the transfer to the new account
2. Check if the old account has enough
3. If yes, subtract the amount from the old account. If not, subtract it back from the new account 

Assume three acounts: A1: $100, A2: $200, A3: $300
``` 
T1 move $150 from A1 -> A2              T2 move $250 from A2 -> A3

Add to A2: $350
                                        Add to A3: $550
Check A1: $100
                                        Check A2: $350 (dirty read)
                                      
Insufficient A2: $200
                                        Sufficient A2: $-50
                            
```

Dirty read has consequences for the Bank application, not so much for the airline reservation

Some cases make sense to allow dirty reads, others do not. 