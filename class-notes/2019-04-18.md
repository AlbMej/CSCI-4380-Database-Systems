# Parallelism in Databases

Databases can generally benefit from parallelism

A parallel machine is basically a collection of processors
- Assume each processor also has a local memory cache

For databases, there are also a large number of disks
- Sometimes one per processors
- Sometimes disks may be accessible by all processors

Parallel systems also have some way of passing data between processors 

3 Broad Categories of system architectures
- Shared Memory
- Shared Disk
- Shared Nothing

## Shared Memory

Each processor has access to the memory of all the others. 

Single physical address space across the entire machine

## Shared Disk

Every processor has its own memory, but they still have access to all the disks

Disk controllers manage competing requests 

Two basic forms:
- Network Attached Storage (NAS): store and transfer files 
- Storage Area Network (SAN): store and transfer blocks

## Shared Nothing

Processors have their own memory and disks

All communication is done via a network, processor to processor. 

Shared nothing is the most common architecture

Relatively inexpensive to build

Algorithms must account for the cost of transferring data
- Typically there's a large fixed-cost for the message, and a small per-byte variable cost
- Try to send large amounts of data at once

## Map/Reduce Parallelism Framework

High-level framework that allows database processes to be written simply

User (developer) writes two functions: map, and reduce

A master controller divides the input data into chunks and assigns processors to run the map function on each chunk.

Other processors (maybe the same ones) peform the reduce function on pieces of the output of the map function

### Storage Model

Assume a massively parallel machine (shared nothing)

Data is stored in files
- Files are typically large (e.g. all the tuples for a relation)

Files are divided into chunks, possibly complete cylinders of a disk, typically many megabytes

Chunks are replicated for resiliency 

### Map/Reduce Functions

Key-value pairs -> map() -> key-value pairs -> sort by key -> reduce() -> output lists per intermediate key

**Map** function takes one key-value pair as input, and it produces a list of key-value pairs as output
- Types of outputs don't have to match the types of inputs
- "Keys" that are output aren't keys in a database sense. Many instances of the same key value can exist
- The map function often doesn't `return` a value in the normal sense. There's often an `emit()` function that's called multiple times

**Reduce** function takes a single intermediate key value, and a list of values associated with that key
- Duplicates are not eliminated 
- Output a single value for that key

Reduce function is often associative and commutative 
- Can be started before the map process is finished 

Example: Inverted index for words in documents 

``` 
map(docId, document) {
    for word in document:
        emit(word, docId)
}

reduce(word, list<docId>) {
    remove duplicates from the list
    insert (word, list<docId>) into index
}
```

Example: Word count

``` 
map(docId, document) {
    for word in document:
        emit(word, 1)
}

reduce(word, list<count>) {
    insert (word, sum(list<count>) into the index 
}
```